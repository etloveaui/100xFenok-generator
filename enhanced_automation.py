#!/usr/bin/env python3
"""
100xFenok Daily Wrap ì™„ì „ ìë™í™” ì‹œìŠ¤í…œ (ë¬´ë£Œ ë²„ì „)
- TerminalX ìë™í™” + Local LLM ê¸°ë°˜ JSON í†µí•©
- ë¬´ë£Œ ë¦¬ì†ŒìŠ¤ë§Œ ì‚¬ìš©í•˜ì—¬ ì™„ì „ ìë™í™” êµ¬í˜„
"""

import os
import json
import time
import logging
from datetime import datetime, timedelta
from pathlib import Path
import subprocess
import requests
from typing import List, Dict, Any, Optional

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('automation.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class FenokAutomationEngine:
    """100xFenok ì™„ì „ ìë™í™” ì—”ì§„"""
    
    def __init__(self):
        self.project_dir = Path(__file__).parent
        self.base_dir = self.project_dir.parent.parent
        
        # ë””ë ‰í„°ë¦¬ ê²½ë¡œ ì„¤ì •
        self.communication_dir = self.base_dir / "communication" / "shared" / "100xfenok"
        self.output_dir = self.base_dir / "projects" / "100xFenok" / "100x" / "daily-wrap"
        self.secrets_file = self.base_dir / "secrets" / "my_sensitive_data.md"
        
        # ë¬´ë£Œ LLM ì„¤ì • (Ollama)
        self.ollama_base_url = "http://localhost:11434"
        self.model_name = "qwen2.5:7b"  # ë˜ëŠ” "llama3.1:8b"
        
        self._ensure_directories()
        
    def _ensure_directories(self):
        """í•„ìš”í•œ ë””ë ‰í„°ë¦¬ ìƒì„±"""
        directories = [
            self.communication_dir / "002_terminalx",
            self.communication_dir / "003_terminalx", 
            self.communication_dir / "004_Lexi_Convert",
            self.communication_dir / "005_Json",
            self.communication_dir / "006_HTML",
            self.output_dir
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            
    def check_ollama_status(self) -> bool:
        """Ollama ì„œë²„ ìƒíƒœ í™•ì¸"""
        try:
            response = requests.get(f"{self.ollama_base_url}/api/tags")
            return response.status_code == 200
        except:
            return False
            
    def setup_ollama(self):
        """Ollama ë° ëª¨ë¸ ì„¤ì¹˜ (ìµœì´ˆ 1íšŒ)"""
        logger.info("Ollama ì„¤ì • í™•ì¸ ì¤‘...")
        
        if not self.check_ollama_status():
            logger.info("Ollama ì„¤ì¹˜ í•„ìš”. ì„¤ì¹˜ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
            # Ollama ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
            subprocess.run(["powershell", "-Command", 
                          "Invoke-WebRequest -UseBasicParsing https://ollama.ai/install.ps1 | Invoke-Expression"],
                          check=True)
            
        # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        logger.info(f"{self.model_name} ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        subprocess.run(["ollama", "pull", self.model_name], check=True)
        
    def call_local_llm(self, prompt: str, system_prompt: str = "") -> str:
        """ë¡œì»¬ LLM í˜¸ì¶œ (ë¬´ë£Œ)"""
        try:
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "system": system_prompt,
                "stream": False
            }
            
            response = requests.post(
                f"{self.ollama_base_url}/api/generate",
                json=payload,
                timeout=300  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
            )
            
            return response.json().get("response", "")
            
        except Exception as e:
            logger.error(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def integrate_json_data(self, part1_files: List[Path], part2_files: List[Path], 
                           html_files: List[Path]) -> Dict[str, Any]:
        """JSON ë°ì´í„° í†µí•© (ë¡œì»¬ LLM ì‚¬ìš©)"""
        logger.info("JSON ë°ì´í„° í†µí•© ì‹œì‘...")
        
        # Instruction í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        instruction_file = self.communication_dir / "005_Json" / "Instruction_Json_20250726.md"
        with open(instruction_file, 'r', encoding='utf-8') as f:
            instruction = f.read()
            
        # ëª¨ë“  ì†ŒìŠ¤ íŒŒì¼ ë‚´ìš© ìˆ˜ì§‘
        source_data = {
            "part1_files": [],
            "part2_files": [],
            "html_files": []
        }
        
        for file_list, key in [(part1_files, "part1_files"), 
                              (part2_files, "part2_files"),
                              (html_files, "html_files")]:
            for file_path in file_list:
                try:
                    if file_path.suffix == '.json':
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = json.load(f)
                    else:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                    
                    source_data[key].append({
                        "filename": file_path.name,
                        "content": content
                    })
                except Exception as e:
                    logger.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ {file_path}: {e}")
        
        # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
{instruction}

=== ì†ŒìŠ¤ ë°ì´í„° ===
{json.dumps(source_data, indent=2, ensure_ascii=False)}

ìœ„ì˜ ì§€ì‹œì‚¬í•­ê³¼ ì†ŒìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ Part1ê³¼ Part2ë¥¼ ê°ê° í†µí•©í•œ JSONì„ ìƒì„±í•´ì£¼ì„¸ìš”.
"""
        
        system_prompt = "ë‹¹ì‹ ì€ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ ìˆ˜ì¤€ì˜ ê¸ˆìœµ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ì§€ì‹œì‚¬í•­ì„ ì •í™•íˆ ë”°ë¼ ê³ í’ˆì§ˆì˜ ê¸ˆìœµ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”."
        
        # LLM í˜¸ì¶œ
        result = self.call_local_llm(prompt, system_prompt)
        
        try:
            # JSON íŒŒì‹± ì‹œë„
            json_start = result.find('{')
            json_end = result.rfind('}') + 1
            if json_start != -1 and json_end != -1:
                json_content = result[json_start:json_end]
                return json.loads(json_content)
        except:
            logger.error("LLM ì‘ë‹µì—ì„œ JSON íŒŒì‹± ì‹¤íŒ¨")
            
        return {}
    
    def generate_final_html(self, part1_json: Dict, part2_json: Dict) -> str:
        """ìµœì¢… HTML ìƒì„±"""
        logger.info("ìµœì¢… HTML ìƒì„± ì‹œì‘...")
        
        # HTML ìƒì„± í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        prompt_file = self.communication_dir / "006_HTML" / "wrap-generate-prompt.txt"
        template_file = self.communication_dir / "006_HTML" / "100x-daily-wrap-template.html"
        agent_file = self.communication_dir / "006_HTML" / "100x-wrap-agent.md"
        
        with open(prompt_file, 'r', encoding='utf-8') as f:
            base_prompt = f.read()
        with open(template_file, 'r', encoding='utf-8') as f:
            template = f.read()
        with open(agent_file, 'r', encoding='utf-8') as f:
            agent_guide = f.read()
            
        # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
{base_prompt}

=== ì—ì´ì „íŠ¸ ê°€ì´ë“œ ===
{agent_guide}

=== í…œí”Œë¦¿ ===
{template}

=== Part 1 ë°ì´í„° ===
{json.dumps(part1_json, indent=2, ensure_ascii=False)}

=== Part 2 ë°ì´í„° ===
{json.dumps(part2_json, indent=2, ensure_ascii=False)}

ìœ„ì˜ í…œí”Œë¦¿ì— Part1ê³¼ Part2 ë°ì´í„°ë¥¼ ì±„ì›Œì„œ ì™„ì „í•œ HTML íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
"""
        
        system_prompt = "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì›¹ ê°œë°œìì´ì ê¸ˆìœµ ë¦¬í¬íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ í…œí”Œë¦¿ì— ë°ì´í„°ë¥¼ ì •í™•íˆ ë§¤í•‘í•˜ì—¬ ì™„ì„±ëœ HTML íŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš”."
        
        # LLM í˜¸ì¶œ
        html_result = self.call_local_llm(prompt, system_prompt)
        
        return html_result
    
    def run_full_automation(self, target_date: str = None) -> bool:
        """ì™„ì „ ìë™í™” ì‹¤í–‰"""
        if not target_date:
            target_date = datetime.now().strftime("%Y-%m-%d")
            
        logger.info(f"=== 100xFenok ì™„ì „ ìë™í™” ì‹œì‘ ({target_date}) ===")
        
        try:
            # 1. Ollama ì„¤ì • í™•ì¸
            if not self.check_ollama_status():
                logger.info("Ollama ì„¤ì • í•„ìš”")
                self.setup_ollama()
                
            # 2. ê¸°ì¡´ TerminalX ìë™í™” ì‹¤í–‰ (1-25ë‹¨ê³„)
            logger.info("TerminalX ìë™í™” ì‹¤í–‰...")
            from main_generator import FenokReportGenerator
            
            terminalx_generator = FenokReportGenerator()
            # ì—¬ê¸°ì— ê¸°ì¡´ TerminalX ìë™í™” ë¡œì§ í˜¸ì¶œ
            
            # 3. ìƒì„±ëœ ë°ì´í„° ìˆ˜ì§‘
            part1_files = list((self.communication_dir / "004_Lexi_Convert").glob("part1_*.json"))
            part2_files = list((self.communication_dir / "004_Lexi_Convert").glob("part2_*.json"))
            html_files = list((self.communication_dir / "003_terminalx").glob("*.html"))
            
            # 4. JSON í†µí•© (26-28ë‹¨ê³„)
            integrated_data = self.integrate_json_data(part1_files, part2_files, html_files)
            
            if not integrated_data:
                logger.error("JSON í†µí•© ì‹¤íŒ¨")
                return False
                
            # 5. ìµœì¢… HTML ìƒì„± (29-34ë‹¨ê³„)
            final_html = self.generate_final_html(
                integrated_data.get("part1", {}),
                integrated_data.get("part2", {})
            )
            
            # 6. ê²°ê³¼ ì €ì¥
            output_file = self.output_dir / f"{target_date.replace('-', '')}_100x-daily-wrap.html"
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(final_html)
                
            logger.info(f"âœ… ìë™í™” ì™„ë£Œ! íŒŒì¼ ìƒì„±: {output_file}")
            return True
            
        except Exception as e:
            logger.error(f"ìë™í™” ì‹¤íŒ¨: {e}")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="100xFenok ì™„ì „ ìë™í™”")
    parser.add_argument("--date", help="ëŒ€ìƒ ë‚ ì§œ (YYYY-MM-DD)")
    parser.add_argument("--setup-only", action="store_true", help="Ollama ì„¤ì •ë§Œ ì‹¤í–‰")
    
    args = parser.parse_args()
    
    engine = FenokAutomationEngine()
    
    if args.setup_only:
        engine.setup_ollama()
        print("âœ… Ollama ì„¤ì • ì™„ë£Œ")
        return
        
    success = engine.run_full_automation(args.date)
    
    if success:
        print("ğŸ‰ 100xFenok ë°ì¼ë¦¬ë© ìë™í™” ì„±ê³µ!")
    else:
        print("âŒ ìë™í™” ì‹¤íŒ¨. ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()