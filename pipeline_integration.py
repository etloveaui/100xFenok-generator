#!/usr/bin/env python3
"""
100xFenok ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•©
- TerminalX ìë™í™” + JSON í†µí•© + HTML ìƒì„± + ê²€ì¦
- ëª¨ë“  ë‹¨ê³„ë¥¼ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì—°ê²°
"""

import os
import sys
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, List, Optional
import time

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from enhanced_automation import FenokAutomationEngine
from data_validator import FinancialDataValidator

# ê¸°ì¡´ TerminalX ìë™í™” ì„í¬íŠ¸ ì‹œë„
try:
    from main_generator import FenokReportGenerator
    TERMINALX_AVAILABLE = True
except ImportError as e:
    TERMINALX_AVAILABLE = False
    logging.warning(f"TerminalX ìë™í™” ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")

logger = logging.getLogger(__name__)

class FullPipelineManager:
    """ì™„ì „ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.automation_engine = FenokAutomationEngine()
        self.validator = FinancialDataValidator()
        self.project_dir = Path(__file__).parent
        
        # ë¡œê·¸ ì„¤ì •
        self._setup_logging()
        
    def _setup_logging(self):
        """ë¡œê¹… ì‹œìŠ¤í…œ ì„¤ì •"""
        log_file = self.project_dir / "pipeline.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        
    def run_complete_pipeline(self, target_date: Optional[str] = None, 
                            skip_terminalx: bool = False) -> Dict[str, Any]:
        """ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        if not target_date:
            target_date = datetime.now().strftime("%Y-%m-%d")
            
        pipeline_result = {
            'success': False,
            'target_date': target_date,
            'stages_completed': [],
            'stages_failed': [],
            'output_files': [],
            'validation_results': {},
            'execution_time': 0,
            'errors': []
        }
        
        start_time = time.time()
        
        try:
            logger.info(f"ğŸš€ 100xFenok ì™„ì „ íŒŒì´í”„ë¼ì¸ ì‹œì‘ - {target_date}")
            
            # Stage 1: TerminalX ë°ì´í„° ìˆ˜ì§‘
            if not skip_terminalx and TERMINALX_AVAILABLE:
                stage1_success = self._execute_terminalx_collection(target_date)
                if stage1_success:
                    pipeline_result['stages_completed'].append('terminalx_collection')
                    logger.info("âœ… Stage 1: TerminalX ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                else:
                    pipeline_result['stages_failed'].append('terminalx_collection')
                    logger.error("âŒ Stage 1: TerminalX ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
            else:
                logger.info("â­ï¸ Stage 1: TerminalX ìë™í™” ê±´ë„ˆë›°ê¸°")
                pipeline_result['stages_completed'].append('terminalx_collection')
                
            # Stage 2: HTML â†’ JSON ë³€í™˜
            stage2_success = self._execute_html_to_json_conversion(target_date)
            if stage2_success:
                pipeline_result['stages_completed'].append('html_to_json')
                logger.info("âœ… Stage 2: HTML â†’ JSON ë³€í™˜ ì™„ë£Œ")
            else:
                pipeline_result['stages_failed'].append('html_to_json')
                logger.error("âŒ Stage 2: HTML â†’ JSON ë³€í™˜ ì‹¤íŒ¨")
                
            # Stage 3: JSON í†µí•© ë° ê²€ì¦
            stage3_result = self._execute_json_integration(target_date)
            if stage3_result['success']:
                pipeline_result['stages_completed'].append('json_integration')
                pipeline_result['validation_results'] = stage3_result['validation']
                logger.info("âœ… Stage 3: JSON í†µí•© ë° ê²€ì¦ ì™„ë£Œ")
            else:
                pipeline_result['stages_failed'].append('json_integration')
                logger.error("âŒ Stage 3: JSON í†µí•© ì‹¤íŒ¨")
                
            # Stage 4: ìµœì¢… HTML ìƒì„±
            stage4_result = self._execute_final_html_generation(target_date, stage3_result.get('data'))
            if stage4_result['success']:
                pipeline_result['stages_completed'].append('html_generation')
                pipeline_result['output_files'].append(stage4_result['output_file'])
                logger.info(f"âœ… Stage 4: HTML ìƒì„± ì™„ë£Œ - {stage4_result['output_file']}")
            else:
                pipeline_result['stages_failed'].append('html_generation')
                logger.error("âŒ Stage 4: HTML ìƒì„± ì‹¤íŒ¨")
                
            # Stage 5: í’ˆì§ˆ ê²€ì¦ ë° í›„ì²˜ë¦¬
            stage5_success = self._execute_quality_check(pipeline_result['output_files'])
            if stage5_success:
                pipeline_result['stages_completed'].append('quality_check')
                logger.info("âœ… Stage 5: í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ")
            else:
                pipeline_result['stages_failed'].append('quality_check')
                logger.warning("âš ï¸ Stage 5: í’ˆì§ˆ ê²€ì¦ì—ì„œ ë¬¸ì œ ë°œê²¬")
                
            # ì „ì²´ ì„±ê³µ ì—¬ë¶€ íŒë‹¨
            pipeline_result['success'] = len(pipeline_result['stages_failed']) == 0
            
        except Exception as e:
            logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            pipeline_result['errors'].append(str(e))
            
        finally:
            pipeline_result['execution_time'] = time.time() - start_time
            logger.info(f"â±ï¸ ì´ ì‹¤í–‰ ì‹œê°„: {pipeline_result['execution_time']:.2f}ì´ˆ")
            
        return pipeline_result
    
    def _execute_terminalx_collection(self, target_date: str) -> bool:
        """Stage 1: TerminalX ë°ì´í„° ìˆ˜ì§‘"""
        try:
            # ê¸°ì¡´ TerminalX ìë™í™” ì‹¤í–‰
            generator = FenokReportGenerator()
            
            # ë‚ ì§œë³„ ë¦¬í¬íŠ¸ ìƒì„± (Part1, Part2 ê°ê° 3ê°œì”©)
            reports_generated = 0
            
            for part in ['part1', 'part2']:
                for i in range(3):
                    try:
                        # ë¦¬í¬íŠ¸ ìƒì„± ì‹œë„
                        success = generator.generate_daily_report(target_date, part, i+1)
                        if success:
                            reports_generated += 1
                            logger.info(f"âœ“ {part} ë¦¬í¬íŠ¸ {i+1} ìƒì„± ì™„ë£Œ")
                        else:
                            logger.warning(f"âš  {part} ë¦¬í¬íŠ¸ {i+1} ìƒì„± ì‹¤íŒ¨")
                            
                    except Exception as e:
                        logger.error(f"âŒ {part} ë¦¬í¬íŠ¸ {i+1} ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
                        
            # ì¶”ê°€ 6ê°œ í”„ë¡¬í”„íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±
            additional_reports = generator.generate_additional_reports(target_date)
            reports_generated += additional_reports
            
            logger.info(f"ğŸ“Š ì´ {reports_generated}ê°œ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
            return reports_generated > 0
            
        except Exception as e:
            logger.error(f"TerminalX ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def _execute_html_to_json_conversion(self, target_date: str) -> bool:
        """Stage 2: HTML â†’ JSON ë³€í™˜"""
        try:
            from converters.html_converter import HTMLToJSONConverter
            
            converter = HTMLToJSONConverter()
            conversion_count = 0
            
            # HTML íŒŒì¼ë“¤ì„ ì°¾ì•„ì„œ ë³€í™˜
            html_dirs = [
                self.automation_engine.communication_dir / "002_terminalx",
                self.automation_engine.communication_dir / "003_terminalx"
            ]
            
            for html_dir in html_dirs:
                if html_dir.exists():
                    for html_file in html_dir.glob("*.html"):
                        try:
                            json_output_path = self.automation_engine.communication_dir / "004_Lexi_Convert" / f"{html_file.stem}.json"
                            success = converter.convert_html_to_json(html_file, json_output_path)
                            if success:
                                conversion_count += 1
                                logger.info(f"âœ“ {html_file.name} â†’ JSON ë³€í™˜ ì™„ë£Œ")
                        except Exception as e:
                            logger.error(f"âŒ {html_file.name} ë³€í™˜ ì‹¤íŒ¨: {e}")
            
            logger.info(f"ğŸ“„ ì´ {conversion_count}ê°œ HTML â†’ JSON ë³€í™˜ ì™„ë£Œ")
            return conversion_count > 0
            
        except ImportError:
            # Python_Lexi_Convertë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë³€í™˜ê¸° ì‚¬ìš©
            logger.info("ê¸°ë³¸ HTML â†’ JSON ë³€í™˜ê¸° ì‚¬ìš©")
            return self._basic_html_to_json_conversion(target_date)
        except Exception as e:
            logger.error(f"HTML â†’ JSON ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def _basic_html_to_json_conversion(self, target_date: str) -> bool:
        """ê¸°ë³¸ HTML â†’ JSON ë³€í™˜ (Python_Lexi_Convert ëŒ€ì²´)"""
        try:
            from bs4 import BeautifulSoup
            import html2text
            
            conversion_count = 0
            h = html2text.HTML2Text()
            h.ignore_links = True
            
            html_dirs = [
                self.automation_engine.communication_dir / "002_terminalx",
                self.automation_engine.communication_dir / "003_terminalx"
            ]
            
            for html_dir in html_dirs:
                if html_dir.exists():
                    for html_file in html_dir.glob("*.html"):
                        try:
                            with open(html_file, 'r', encoding='utf-8') as f:
                                html_content = f.read()
                            
                            # Beautiful Soupìœ¼ë¡œ íŒŒì‹±
                            soup = BeautifulSoup(html_content, 'html.parser')
                            
                            # ê¸°ë³¸ì ì¸ JSON êµ¬ì¡° ìƒì„±
                            json_data = {
                                "source_file": html_file.name,
                                "conversion_date": datetime.now().isoformat(),
                                "content": []
                            }
                            
                            # í…Œì´ë¸” ì¶”ì¶œ
                            for table in soup.find_all('table'):
                                table_data = self._extract_table_data(table)
                                if table_data:
                                    json_data["content"].append(table_data)
                            
                            # í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ
                            text_content = h.handle(html_content)
                            if text_content.strip():
                                json_data["content"].append({
                                    "type": "text",
                                    "content": text_content.strip()
                                })
                            
                            # JSON íŒŒì¼ ì €ì¥
                            json_output_path = self.automation_engine.communication_dir / "004_Lexi_Convert" / f"{html_file.stem}.json"
                            with open(json_output_path, 'w', encoding='utf-8') as f:
                                json.dump(json_data, f, indent=2, ensure_ascii=False)
                            
                            conversion_count += 1
                            logger.info(f"âœ“ {html_file.name} â†’ JSON ë³€í™˜ ì™„ë£Œ (ê¸°ë³¸ ë³€í™˜ê¸°)")
                            
                        except Exception as e:
                            logger.error(f"âŒ {html_file.name} ê¸°ë³¸ ë³€í™˜ ì‹¤íŒ¨: {e}")
            
            return conversion_count > 0
            
        except Exception as e:
            logger.error(f"ê¸°ë³¸ HTML â†’ JSON ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def _extract_table_data(self, table_element) -> Optional[Dict[str, Any]]:
        """HTML í…Œì´ë¸”ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
        try:
            rows = table_element.find_all('tr')
            if not rows:
                return None
                
            table_data = {
                "type": "table",
                "headers": [],
                "data": []
            }
            
            # í—¤ë” ì¶”ì¶œ
            header_row = rows[0]
            headers = header_row.find_all(['th', 'td'])
            table_data["headers"] = [header.get_text().strip() for header in headers]
            
            # ë°ì´í„° í–‰ ì¶”ì¶œ
            for row in rows[1:]:
                cells = row.find_all(['td', 'th'])
                row_data = [cell.get_text().strip() for cell in cells]
                if any(row_data):  # ë¹ˆ í–‰ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
                    table_data["data"].append(row_data)
            
            return table_data if table_data["data"] else None
            
        except Exception as e:
            logger.error(f"í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _execute_json_integration(self, target_date: str) -> Dict[str, Any]:
        """Stage 3: JSON í†µí•© ë° ê²€ì¦"""
        result = {'success': False, 'data': {}, 'validation': {}}
        
        try:
            # JSON íŒŒì¼ë“¤ ìˆ˜ì§‘
            json_dir = self.automation_engine.communication_dir / "004_Lexi_Convert"
            part1_files = list(json_dir.glob("part1_*.json"))
            part2_files = list(json_dir.glob("part2_*.json"))
            html_files = list(self.automation_engine.communication_dir.glob("003_terminalx/*.html"))
            
            # ë¡œì»¬ LLMìœ¼ë¡œ JSON í†µí•©
            integrated_data = self.automation_engine.integrate_json_data(
                part1_files, part2_files, html_files
            )
            
            if integrated_data:
                # ë°ì´í„° ê²€ì¦
                validation_results = self.validator.validate_json_data(integrated_data)
                
                result['success'] = True
                result['data'] = integrated_data
                result['validation'] = validation_results
                
                # ê²€ì¦ ê²°ê³¼ ë¡œê¹…
                if validation_results['errors']:
                    logger.warning(f"âš ï¸ ê²€ì¦ì—ì„œ {len(validation_results['errors'])}ê°œ ì˜¤ë¥˜ ë°œê²¬")
                    for error in validation_results['errors']:
                        logger.warning(f"  - {error}")
                
                logger.info(f"ğŸ“Š í’ˆì§ˆ ì ìˆ˜: {validation_results.get('quality_score', 0)}/100")
                
        except Exception as e:
            logger.error(f"JSON í†µí•© ì¤‘ ì˜¤ë¥˜: {e}")
            result['success'] = False
            
        return result
    
    def _execute_final_html_generation(self, target_date: str, integrated_data: Optional[Dict]) -> Dict[str, Any]:
        """Stage 4: ìµœì¢… HTML ìƒì„±"""
        result = {'success': False, 'output_file': None}
        
        try:
            if not integrated_data:
                logger.error("í†µí•©ëœ JSON ë°ì´í„°ê°€ ì—†ìŒ")
                return result
                
            # HTML ìƒì„±
            final_html = self.automation_engine.generate_final_html(
                integrated_data.get('part1', {}),
                integrated_data.get('part2', {})
            )
            
            if final_html:
                # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
                date_str = target_date.replace('-', '')
                output_file = self.automation_engine.output_dir / f"{date_str}_100x-daily-wrap.html"
                
                # íŒŒì¼ ì €ì¥
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(final_html)
                
                result['success'] = True
                result['output_file'] = str(output_file)
                
                logger.info(f"ğŸ“„ ìµœì¢… HTML ìƒì„±: {output_file}")
                
        except Exception as e:
            logger.error(f"HTML ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            
        return result
    
    def _execute_quality_check(self, output_files: List[str]) -> bool:
        """Stage 5: í’ˆì§ˆ ê²€ì¦"""
        try:
            for output_file in output_files:
                if os.path.exists(output_file):
                    # íŒŒì¼ í¬ê¸° í™•ì¸
                    file_size = os.path.getsize(output_file)
                    if file_size < 1000:  # 1KB ë¯¸ë§Œ
                        logger.warning(f"âš ï¸ ì¶œë ¥ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŒ: {output_file} ({file_size} bytes)")
                        return False
                    
                    # HTML ìœ íš¨ì„± ê¸°ë³¸ í™•ì¸
                    with open(output_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                    if not content.strip().startswith('<!DOCTYPE html>'):
                        logger.warning(f"âš ï¸ HTML ë¬¸ì„œ íƒ€ì…ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ: {output_file}")
                        return False
                        
                    if '<title>' not in content:
                        logger.warning(f"âš ï¸ HTML ì œëª©ì´ ì—†ìŒ: {output_file}")
                        return False
                        
                    logger.info(f"âœ“ í’ˆì§ˆ ê²€ì¦ í†µê³¼: {output_file}")
                    
            return True
            
        except Exception as e:
            logger.error(f"í’ˆì§ˆ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="100xFenok ì™„ì „ íŒŒì´í”„ë¼ì¸")
    parser.add_argument("--date", help="ëŒ€ìƒ ë‚ ì§œ (YYYY-MM-DD)")
    parser.add_argument("--skip-terminalx", action="store_true", help="TerminalX ìë™í™” ê±´ë„ˆë›°ê¸°")
    parser.add_argument("--test-run", action="store_true", help="í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©)")
    
    args = parser.parse_args()
    
    pipeline = FullPipelineManager()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    if args.test_run:
        args.skip_terminalx = True
        print("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ê¸°ì¡´ ë°ì´í„°ë¡œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    result = pipeline.run_complete_pipeline(
        target_date=args.date,
        skip_terminalx=args.skip_terminalx
    )
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼")
    print("="*60)
    print(f"âœ… ì„±ê³µ: {result['success']}")
    print(f"ğŸ“… ëŒ€ìƒ ë‚ ì§œ: {result['target_date']}")
    print(f"â±ï¸ ì‹¤í–‰ ì‹œê°„: {result['execution_time']:.2f}ì´ˆ")
    print(f"âœ“ ì™„ë£Œëœ ë‹¨ê³„: {len(result['stages_completed'])}")
    print(f"âŒ ì‹¤íŒ¨í•œ ë‹¨ê³„: {len(result['stages_failed'])}")
    
    if result['output_files']:
        print(f"ğŸ“„ ìƒì„±ëœ íŒŒì¼:")
        for file_path in result['output_files']:
            print(f"  - {file_path}")
    
    if result['validation_results']:
        quality_score = result['validation_results'].get('quality_score', 0)
        print(f"ğŸ¯ í’ˆì§ˆ ì ìˆ˜: {quality_score}/100")
    
    if result['errors']:
        print(f"âš ï¸ ì˜¤ë¥˜:")
        for error in result['errors']:
            print(f"  - {error}")

if __name__ == "__main__":
    main()